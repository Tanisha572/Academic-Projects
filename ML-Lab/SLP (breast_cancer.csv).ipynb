{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SINGLE LAYER PERCEPTRON (breast cancer dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loading dataset and setting X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer_data = load_breast_cancer()\n",
    "X = cancer_data.data\n",
    "y = cancer_data.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
      " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
      " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
      " ...\n",
      " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
      " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
      " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### label encoding for y (M or B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reshaping X and y to form matrices using closed form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of samples/rows: 569\n",
      "no. of input features: 30, namely: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "X.shape: (569, 30)\n",
      "y.shape: (569, 1)\n",
      "\n",
      "after adding one column, updated shape for X: 31\n"
     ]
    }
   ],
   "source": [
    "rows = X.shape[0]\n",
    "columns = X.shape[1]\n",
    "#y has a shape of (569,) i.e 569 rows. to make it explicity a 1d np array, we'll reshape it with cols=1\n",
    "y = y.reshape(y.shape[0], 1)\n",
    "print(\"no. of samples/rows: {}\\nno. of input features: {}, namely: {}\".format(rows, columns, cancer_data.feature_names))\n",
    "print(\"X.shape: {}\".format(X.shape))\n",
    "print(\"y.shape: {}\\n\".format(y.shape))\n",
    "\n",
    "ones = np.ones((rows, 1))\n",
    "\n",
    "#adding this ones column to X\n",
    "X = np.concatenate((ones, X), axis=1)\n",
    "#for updated X, first col of 1s represents x0 i.e 1(coef of intercept), \n",
    "#other columns represent other attributes\n",
    "#no. columns gets updated by 1\n",
    "columns = X.shape[1]\n",
    "print('after adding one column, updated shape for X: {}'.format(X.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train test split of (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 31) (455, 1)\n",
      "(114, 31) (114, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "#always fit_transform on training set and as testing set is unseen, we'll use transform to normalise\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### defining learning rate and #iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_rate = 0.1\n",
    "n_epochs = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### estimating perceptron weights using stochastic gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, weights):\n",
    "    activation = X.dot(weights)\n",
    "    prediction = np.where(activation >= 0.0, 1.0, 0.0)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_weights(X, y, l_rate, n_epochs):\n",
    "    weights = np.zeros((columns, 1))\n",
    "    for i in range(n_epochs):\n",
    "        prediction = predict(X, weights)\n",
    "        error = y - prediction\n",
    "        weights[0] = weights[0] + l_rate*error[0]\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(1, columns):\n",
    "                weights[j] = weights[j] + l_rate*error[j]*X[i][j]\n",
    "        #weights = weights + l_rate*(((error.T).dot(X)/rows).T)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training our model and adjusting weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.00000000e+02 -2.30698793e-11  2.12274753e-10 -4.26048086e-14\n",
      "  -4.55191440e-15 -3.46044964e-11  7.09803744e-12 -2.26484873e-11\n",
      "   0.00000000e+00  4.45421505e-10  2.26259081e-10  0.00000000e+00\n",
      "  -4.63656891e-14  2.70896916e-11 -2.39328557e-11  4.96880037e-11\n",
      "   7.09840520e-12  1.24900090e-13  3.68108322e-14 -8.69549294e-11\n",
      "   2.17385415e-11 -1.38491441e-11  0.00000000e+00 -1.27009625e-10\n",
      "  -9.75041714e-11 -8.59659566e-14 -9.18344394e-11  2.22807883e-14\n",
      "  -7.56478213e-14 -9.22781998e-11  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "weights = train_weights(X_train, y_train, l_rate, n_epochs)\n",
    "print(weights.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predicting label for test set using the weights obtained during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label = predict(X_test, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### getting F1 score, accuracy and ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "f1 score : 0.55552\n",
      "accuracy score : 0.54386\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "acc = accuracy_score(y_test,pred_label).round(5)\n",
    "f1 = f1_score(y_test, pred_label, average='weighted').round(5)\n",
    "print(\"\\nf1 score : {}\".format(f1))\n",
    "print(\"accuracy score : {}\".format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
